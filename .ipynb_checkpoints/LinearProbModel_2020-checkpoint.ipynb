{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys                         # import operating system functions\n",
    "import numpy as np                  # pandas uses numpy, and sometimes want to use numpy within pandas\n",
    "import pandas as pd                    # data package, redundant since already did\n",
    "import matplotlib.pyplot as plt               # graphics package, just the part we mainly use\n",
    "import seaborn as sns               # makes matplotlib prettier without issuing a single command!\n",
    "import datetime as dt                  # date and time module, often need to use if date is a field in your data\n",
    "\n",
    "# check versions (overkill, but why not?)\n",
    "print('Python version:', sys.version)\n",
    "print('Pandas version: ', pd.__version__)\n",
    "# print ('Matplotlib version:',matplotlib.__version__) #command not in the pyplot piece of matplotlib, would need to import entire package\n",
    "print('Today: ', dt.date.today())\n",
    "print(plt.style.available)\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Probability Models\n",
    "> Kenneth Flamm\n",
    "\n",
    "> Spring 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear probability models\n",
    "* Fell out of fashion in the 1980s and 1990s\n",
    "    \n",
    "* Back in fashion among economists and econometricians\n",
    "    \n",
    "    * Can be viewed as approximation to logit or probit (which generally yield nearly identical results)\n",
    "   [von Hippel article](https://statisticalhorizons.com/linear-vs-logistic)\n",
    "    \n",
    "    * should give similar results for probabilities in .2 to .8 range\n",
    "    \n",
    "    * generally does give similar empirical results to logit or probit for non-rare events\n",
    "    \n",
    "    * huge gains in ease of use\n",
    "    \n",
    "    * not obviously worse as approximation to unknown distribution than logit or probit parametric assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Good vehicle for taking about heteroskedasticity\n",
    "\n",
    "* linear probability model is inherently heteroskedastic\n",
    "\n",
    "* LPM: \n",
    "* probability of event occurring is approximately linear function of x's\n",
    "    * $P(y=1 | x) = \\beta_0 + \\sum_i \\beta_i x_i$ , so\n",
    "    * $ E(y | x) = \\beta_0 + \\sum_i \\beta_i x_i$\n",
    "    * and if we change x_i while holding all other factors fixed, then\n",
    "    * $\\Delta P (y=1 | x) = \\beta_i \\Delta x_i$\n",
    "        * can interpret $\\beta_i $ as marginal effect of 1 unit change in $x_i$ on probability of event\n",
    "        \n",
    "* a binary random variable y=1 with P(y=1|x) has variance  = $ P(y=1|x) * (1-P(y=1|x))  $\n",
    "    * This is obviously not constant, and will vary with x.\n",
    "    * Heteroskedasticity guaranteed!\n",
    "    \n",
    "* See appropriate sections in Wooldridge, chaps. 7 & 8.\n",
    "\n",
    "Let's take another look at that apple data.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use apple.data\n",
    "apdf=pd.read_stata('http://fmwww.bc.edu/ec-p/data/wooldridge/apple.dta') \n",
    "apdf.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lots of zeros in apple consumption data\n",
    "* a lot of mothers apparently didn't tell their children \"an apple a day...\"\n",
    "\n",
    "* Let's code up a y-variable for buying any eco apples at all.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apdf.loc[:,'buy_eco']=0\n",
    "apdf.loc[(apdf.ecolbs > 0),'buy_eco']=1\n",
    "apdf.loc[:,'buy_reg']=0\n",
    "apdf.loc[(apdf.reglbs > 0),'buy_reg']=1\n",
    "apdf[['buy_eco','buy_reg']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **38% of households wouldn't buy any eco apples given apple prices they were informed of!**\n",
    "\n",
    "> **52% of households wouldn't buy any reg apples at these prices!**\n",
    "\n",
    "> model probability of buying an eco apple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear probability model\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.compat import lzip # useful for printing out complicated test statistics, see below\n",
    "mod=smf.ols('buy_eco ~ ecoprc + regprc + faminc + hhsize + educ + age',apdf)\n",
    "res=mod.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's test for heteroskedasticity using the Breusch-Pagan test and White test\n",
    "    * discussed in Wooldridge, chap. 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms.het_breuschpagan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breusch-Pagan test\n",
    "# null hypothesis is homoskedasticity\n",
    "name = ['Lagrange multiplier statistic', 'p-value',\n",
    "        'f-value', 'f p-value']\n",
    "test = sms.het_breuschpagan(res.resid,res.model.exog)\n",
    "lzip(name, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms.het_white?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# White test\n",
    "# null hypothesis is homoskedasticity\n",
    "name = ['Lagrange multiplier statistic', 'p-value',\n",
    "        'f-value', 'f p-value']\n",
    "test = sms.het_white(res.resid,res.model.exog)\n",
    "lzip(name, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['Lagrange multiplier statistic', 'p-value',\n",
    "        'f-value', 'f p-value']\n",
    "test = sms.het_white(res.resid,res.model.exog)\n",
    "lzip(name, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we reject null (homoskedasticity) decisively!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solution #1: robust standard errors\n",
    "\n",
    "* What are we now assuming?\n",
    "\n",
    "    * Different observations have different variances\n",
    "    \n",
    "    * Disturbance terms uncorrelated across observations still assumed though\n",
    "    \n",
    "* What do we lose?\n",
    "\n",
    "    * Efficiency: no longer minimum variance linear estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear probability model\n",
    "# with robust standard errors\n",
    "mod_r=smf.ols('buy_eco ~ ecoprc + regprc + faminc + hhsize + educ + age',apdf)\n",
    "res_r=mod_r.fit(cov_type='HC3')\n",
    "res_r.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that coefficient estimates identical to OLS, only SEs have changed\n",
    "\n",
    "* Not that different in this case, but can be bigger or smaller, in general\n",
    "\n",
    "* Biggest problem with LPM is when probability p is close to zero or one\n",
    "\n",
    "* In this case, linear model allows p to be negative or > 1, which is an issue for predictions\n",
    "\n",
    "* Do we have this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_r.fittedvalues.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> No negative values!\n",
    "\n",
    "> But we do have at least one observation with predicted prob > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_r.fittedvalues[(res_r.fittedvalues>1)].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So we have two such predictions that are out of bounds....\n",
    "\n",
    "#### Solution #2: weighted least squares, AKA Feasible GLS\n",
    "\n",
    "* Idea: we estimate size of variance, observation by observation, using a statistical model\n",
    "\n",
    "    * See Wooldridge, chap. 8.\n",
    "\n",
    "* If predicted variance conditional on x is $h \\sigma^2$\n",
    "\n",
    "* transform all variables (including constant) by multiplying by $\\frac{1}{\\sqrt{h}}$\n",
    "    * resulting transformed model has homoskedastic disturbances\n",
    "    * Can then estimate model using OLS\n",
    "    * satisfies conditions guaranteeing minimum variance unbiased linear estimator\n",
    "    * statsmodels will do all this automatically using **WLS** estimation command\n",
    "        * you pass it a vector of weights  $\\frac{1}{{h}}$ i.e., the inverse of the variance, not the sd\n",
    "        * WLS requires that the weights are proportional to the inverse of the error variance\n",
    "\n",
    "* ***But,*** \n",
    "    * if function used to estimate h is wrong\n",
    "        * no guarantee estimate will be more efficient than OLS, could be less\n",
    "        * disturbance term will still be heteroskedastic, inference incorrect\n",
    "        * but you could then use robust standard errors to hedge your bets!\n",
    "    * even if the function used to estimate h is right\n",
    "        * all estimated standard errors, statistical inference is only asymptotically correct\n",
    "        * because you estimated heteroskedasticity (not known with certainty)\n",
    "            * you are relying on consistency of variance estimate\n",
    "            * to deliver estimated variance close to true value, requires large sample\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying this approach to LPM:\n",
    "\n",
    "* variance of y (probability) is just p * (1-p) = $ \\hat{y} * (1 - \\hat{y})$\n",
    "* so $ h = \\hat{y} * (1 - \\hat{y})$\n",
    "\n",
    "* Steps:\n",
    "    1. get $\\hat{y}$\n",
    "    2. replace $\\hat{y}$ with .99 if > 1, .01 if < 0\n",
    "    3. estimate model using WLS after passing weights $\\frac{1}{h}$\n",
    "* Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apdf.loc[:,'p_hat']=res_r.fittedvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apdf.p_hat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apdf.loc[(apdf.p_hat>1),'p_hat']=.99\n",
    "apdf.loc[:,'w']=1/(apdf.p_hat*(1-apdf.p_hat))\n",
    "apdf[['p_hat','w']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_w=sm.WLS.from_formula('buy_eco ~ ecoprc + regprc + faminc + hhsize + educ + age',\n",
    "              apdf,weights=apdf.w)\n",
    "res_w=mod_w.fit()\n",
    "res_w.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_wr=sm.WLS.from_formula('buy_eco ~ ecoprc + regprc + faminc + hhsize + educ + age',\n",
    "              apdf,weights=apdf.w)\n",
    "res_wr=mod_wr.fit(cov_type='HC3')\n",
    "res_wr.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare estimated coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.iolib.table import (SimpleTable, default_txt_fmt)\n",
    "beta = np.vstack([[res.params], [res_r.params], [res_w.params],[res_wr.params]])\n",
    "beta = np.round(beta,5)\n",
    "colnames = ['const', 'ecoprc','regprc','faminc','hhsize','educ','age']\n",
    "rownames = ['OLS', 'OLS_rob', 'WLS','WLS_HC3']\n",
    "tabl = SimpleTable(beta, colnames, rownames, txt_fmt=default_txt_fmt)\n",
    "tabl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare various standard errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = np.vstack([[res.bse], [res_r.bse], [res_w.bse],[res_wr.bse],[res.HC0_se], \n",
    "                [res.HC1_se], [res.HC2_se], [res.HC3_se]])\n",
    "se = np.round(se,5)\n",
    "colnames = ['const', 'ecoprc','regprc','faminc','hhsize','educ','age']\n",
    "rownames = ['OLS', 'OLS_rob', 'WLS','WLS_HC3','OLS_HC0', 'OLS_HC1', 'OLS_HC2', 'OLS_HC3']\n",
    "tabl = SimpleTable(se, colnames, rownames, txt_fmt=default_txt_fmt)\n",
    "print(tabl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In class Exercise: Define variable for buy reg apple, estimate LPM using OLS with robust se, and WLS with robust se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.WLS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.GLS?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
